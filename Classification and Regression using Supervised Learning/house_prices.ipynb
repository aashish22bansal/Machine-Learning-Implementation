{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c09848",
   "metadata": {},
   "source": [
    "# **House Price Prediction**\n",
    "---\n",
    "Basic Regression Model\n",
    "---\n",
    "This notebook builds a basic house price prediction model using Support Vector Regression (SVR) from scikit-learn as:\n",
    "1. Imports necessary libraries for data handling, modeling, and evaluation.\n",
    "2. Loads the Boston housing dataset (note: this will fail in scikit-learn ≥1.2).\n",
    "3. Shuffles the dataset for randomness.\n",
    "4. Splits the data into training (80%) and testing (20%) sets.\n",
    "5. Creates and trains an SVR model with a linear kernel.\n",
    "6. Evaluates the model’s performance using mean squared error and explained variance score.\n",
    "7. Predicts the price for a sample test datapoint and prints the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9da22d",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250ec744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41108f72",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "124eee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = datasets.load_boston()\n",
    "# `load_boston` has been removed from scikit-learn since version 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099b221e",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------\n",
    "ImportError                               Traceback (most recent call last)\n",
    "Cell In[2], line 1\n",
    "----> 1 data = datasets.load_boston()\n",
    "\n",
    "File c:\\Users\\aashi\\GitHub\\9781786464392\\venv\\Lib\\site-packages\\sklearn\\datasets\\__init__.py:161, in __getattr__(name)\n",
    "    110 if name == \"load_boston\":\n",
    "    111     msg = textwrap.dedent(\n",
    "    112         \"\"\"\n",
    "    113         `load_boston` has been removed from scikit-learn since version 1.2.\n",
    "   (...)    159         \"\"\"\n",
    "    160     )\n",
    "--> 161     raise ImportError(msg)\n",
    "    162 try:\n",
    "    163     return globals()[name]\n",
    "\n",
    "ImportError: \n",
    "`load_boston` has been removed from scikit-learn since version 1.2.\n",
    "\n",
    "The Boston housing prices dataset has an ethical problem: as\n",
    "investigated in [1], the authors of this dataset engineered a\n",
    "non-invertible variable \"B\" assuming that racial self-segregation had a\n",
    "positive impact on house prices [2]. Furthermore the goal of the\n",
    "research that led to the creation of this dataset was to study the\n",
    "impact of air quality but it did not give adequate demonstration of the\n",
    "validity of this assumption.\n",
    "\n",
    "The scikit-learn maintainers therefore strongly discourage the use of\n",
    "this dataset unless the purpose of the code is to study and educate\n",
    "about ethical issues in data science and machine learning.\n",
    "\n",
    "In this special case, you can fetch the dataset from the original\n",
    "source::\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "    target = raw_df.values[1::2, 2]\n",
    "\n",
    "Alternative datasets include the California housing dataset and the\n",
    "Ames housing dataset. You can load the datasets as follows::\n",
    "\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    housing = fetch_california_housing()\n",
    "\n",
    "for the California housing dataset and::\n",
    "\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
    "\n",
    "for the Ames housing dataset.\n",
    "\n",
    "[1] M Carlisle.\n",
    "\"Racist data destruction?\"\n",
    "<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n",
    "\n",
    "[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n",
    "\"Hedonic housing prices and the demand for clean air.\"\n",
    "Journal of environmental economics and management 5.1 (1978): 81-102.\n",
    "<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763e017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "data = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d365c77d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "This will load a similar regression dataset suitable for house price prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bccee51",
   "metadata": {},
   "source": [
    "# Shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b7fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(data.data, data.target, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488cfa42",
   "metadata": {},
   "source": [
    "# Split the data into training and testing datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e4b0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training = int(0.8 * len(X))\n",
    "X_train, y_train = X[:num_training], y[:num_training]\n",
    "X_test, y_test = X[num_training:], y[num_training:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0ae11",
   "metadata": {},
   "source": [
    "# Create Support Vector Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b9ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_regressor = SVR(kernel='linear', C=1.0, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e00f535",
   "metadata": {},
   "source": [
    "# Train Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962b18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3af891a",
   "metadata": {},
   "source": [
    "# Evaluate performance of Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da58592",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = sv_regressor.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_test_pred)\n",
    "evs = explained_variance_score(y_test, y_test_pred) \n",
    "print(\"\\n#### Performance ####\")\n",
    "print(\"Mean squared error =\", round(mse, 2))\n",
    "print(\"Explained variance score =\", round(evs, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133c0f5",
   "metadata": {},
   "source": [
    "# Test the regressor on test datapoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fd310",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [3.7, 0, 18.4, 1, 0.87, 5.95, 91, 2.5052, 26, 666, 20.2, 351.34, 15.27]\n",
    "print(\"\\nPredicted price:\", sv_regressor.predict([test_data])[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
